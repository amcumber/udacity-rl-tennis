[environment]
ENV_FILE = 'envs\Tennis_Windows_x86_64\Tennis.exe'
# ENV_FILE = "/data/Tennis_Linux_NoVis/Tennis"
# ENV_TYPE = 'tennis'        # enum ('unity', 'gym') = choose which environment to run
STATE_SIZE = 24            # State size for given environment
ACTION_SIZE = 2            # Action size for given environment
UPPER_BOUND = 1.0          # upper bound of action space
SOLVED = 0.5               # Score to be considered solved for given environment
ROOT_NAME = 'tennis'       # root name for save files

[trainer]
BATCH_SIZE = 16            # minibatch size
N_EPISODES = 1000          # max number of episodes to run
MAX_T = 2000               # Max time steps within an episode
WINDOW_LEN = 100           # window length for averaging

[agent]
N_AGENTS = 2
BUFFER_SIZE = 1000000      # Replay buffer size
LEARN_F = 20               # Learning Frequency within episodes
GAMMA = 0.99               # discount factor
TAU = 1e-3                 # soft update target parameter
LR_ACTOR = 1e-4            # learning rate for the actor
LR_CRITIC = 1e-4           # learning rate for the critic
WEIGHT_DECAY = 0.0         # (0.0001) L2 weight decay parameter
ACTOR_HIDDEN = [64, 64]    # Actor Hidden architecture s -> h1 -> ... -> hn -> a
CRITIC_HIDDEN = [64, 64]   # Critic s -> h1+a -> ... -> hn -> 1
ACTOR_ACT = 'relu'         # Actor Activation Function
CRITIC_ACT = 'leaky_relu'  # Actor Activation Function
ADD_NOISE = [false, false] # [false | "OU" | "Stocastic" ] add noise to the agent's action
SEED = 42                  # random seed